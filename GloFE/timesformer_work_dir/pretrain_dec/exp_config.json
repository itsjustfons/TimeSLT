{"activation": "gelu", "bs": 4, "clip_length": 512, "dec_pre_trained": "True", "dim_embedding": 768, "dim_forward_dec": 1024, "dim_forward_enc": 1024, "dropout_dec": 0.1, "dropout_enc": 0.1, "eos_token": "</s>", "epochs": 400, "feat_path": "/data/group1/z40575r/TimeSformer_GloFE/TimeSformer/datasets/how2sign/256", "frames16": true, "froze_vb": false, "inter_cl": false, "inter_cl_alpha": 1.0, "inter_cl_margin": 0.4, "inter_cl_vocab": 2191, "inter_cl_we_dim": 300, "inter_cl_we_path": "./GloFE/notebooks/openasl-v1.0/uncased_filtred_glove_VN_embed.pkl", "label_path": "/data/group1/z40575r/CorrNet/how2sign/annotations/how2sign_realigned_combined.tsv", "local_rank": 0, "lr": 0.0003, "ls": 0.2, "mask_enc": true, "mask_future": true, "max_gen_tks": 35, "ngpus": 1, "nhead_dec": 8, "nhead_enc": 8, "norm_first": false, "num_beams": 5, "num_dec": 4, "num_enc": 4, "pe_enc": true, "phase": "train", "pose_backbone": "PartedPoseBackbone", "prefix": "phoenix_prefix", "resume": -1, "save_every": 1, "seed": 42, "split": "dev", "tokenizer": "/data/group1/z40575r/TimeSformer_GloFE/GloFE/notebooks/how2sign/how2sign-bpe25000-tokenizer-uncased", "vocab_size": 23136, "warm_up": 1000, "weights": null, "work_dir": "pretrain_dec/", "work_dir_prefix": "./timesformer_work_dir"}